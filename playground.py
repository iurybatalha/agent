from textwrap import dedent

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.knowledge.csv import CSVKnowledgeBase, CSVReader
from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader
from agno.knowledge.text import TextKnowledgeBase, TextReader
from agno.knowledge.markdown import MarkdownKnowledgeBase, MarkdownReader
from agno.vectordb.lancedb import LanceDb
from agno.vectordb.search import SearchType
from agno.embedder.ollama import OllamaEmbedder
from agno.models.ollama import OllamaTools
from agno.storage.sqlite import SqliteStorage
from agno.playground import Playground


## agent storage
agent_storage: str = "tmp/agents.db"

# whitch archive type
type = "pdf"
db_name = "Markdown"

vector_db = LanceDb(
    table_name=db_name,
    uri="/tmp/lancedb",
    embedder=OllamaEmbedder(id="nomic-embed-text", dimensions=768),
    search_type=SearchType.keyword,
)
if 'pdf' == type:
    knowledge_base = PDFKnowledgeBase(
        #urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        path="Knowledge/Semantic_Successive_Refinement_A_Generative_AI-Aided_Semantic_Communication_Framework.pdf",
        #path="knowlegde/survey.pdf",
        vector_db=vector_db,
        reader=PDFReader(chunk=True),
    )
elif 'csv' == type:
    # Knowledge Base
    knowledge_base = CSVKnowledgeBase(
        #urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        path="Knowledge/Products_Modem_Management_Upgrade_Team.csv",
        #path="knowlegde/survey.pdf",
        vector_db=vector_db,
        reader=CSVReader(chunk=True),
    )
elif 'txt' == type:
    knowledge_base = TextKnowledgeBase(
        path="Knowledge/cases",
        vector_db=vector_db,
        reader = TextReader(chunk=True)
    )
elif 'url' == type:
    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=vector_db,
        reader=PDFReader(chunk=True),
    )
elif 'md' == type:
    print("Markdown")
    knowledge_base = MarkdownKnowledgeBase(
        path="Knowledge/Products.md",
        vector_db=vector_db,
        reader = MarkdownReader()
    )
else:
    print("Invalid type")
    exit()

Agent_ai = Agent(
    model=OllamaTools(
        id="llama3.1:8b",
        #id="deepseek-r1:8b",
        #max_tokens=4096,
        ), 
    markdown=True,
    name="SpeedAi",
    user_id="SpeeDa",
    knowledge=knowledge_base,
    show_tool_calls=True,
    debug_mode=True,
    read_tool_call_history = True,
    storage=SqliteStorage(table_name="Speed_Agent", db_file=agent_storage),
    add_datetime_to_instructions=True,
    add_history_to_messages=True,
    num_history_responses=5,
    description=dedent("""\
        You are a distinguished analist with expertise in csv files
        with analyzing and synthesizing complex information. Your specialty is analyses the csv files and check the lines and rows, 
        get links present in your knowlegde base associate with request
        and check the similarity of the another lines and/or rows are similar fact-based reports that uses the knowledge.
    """),
    instructions=dedent("""\
        Search for information request in by the user in the knowledge base and get the line and row, 
        after search in the row the information associate with the request and capture these informations, 
        return the information found in the knowledge base.
    """),
    expected_output=dedent("""\
    ## Key Findings
    {shows the keywords}
    {shows the information found in the knowledge base}

    ## References
    - [Source 1](link) - Key finding/quote

    ---
    Report generated by analist 
    Date: {current_date}\
    """),
    )

playground_app = Playground(agents=[Agent_ai])
app = playground_app.get_app()

if __name__ == "__main__":
    playground_app.serve("playground:app", reload=True)



